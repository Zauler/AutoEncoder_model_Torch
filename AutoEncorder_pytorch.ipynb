{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.parallel \n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATASETS\n",
    "movies = pd.read_csv(\"ml-1m/ml-1m/movies.dat\", sep = \"::\", header = None, engine = \"python\", encoding = \"latin-1\")\n",
    "users = pd.read_csv(\"ml-1m/ml-1m/users.dat\", sep = \"::\", header = None, engine = \"python\", encoding = \"latin-1\")\n",
    "ratings = pd.read_csv(\"ml-1m/ml-1m/ratings.dat\", sep = \"::\", header = None, engine = \"python\", encoding = \"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training set and the testing set\n",
    "training_set = pd.read_csv(\"ml-100k/ml-100k/u1.base\", sep = \"\\t\", header=  None)\n",
    "training_set = np.array(training_set, dtype = \"int\")\n",
    "\n",
    "test_set = pd.read_csv(\"ml-100k/ml-100k/u1.test\", sep = \"\\t\", header=  None)\n",
    "test_set = np.array(test_set, dtype = \"int\")\n",
    "\n",
    "# to obtain the number of users and number of films \n",
    "nb_users = int(max(max(training_set[:,0]),max(test_set[:,0])))\n",
    "nb_movies = int(max(max(training_set[:,1]),max(test_set[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data into an array X[u,i] with users u in row and movies i in column \n",
    "def convert(data):\n",
    "    new_data = []\n",
    "    for id_users in range(1,nb_users+1):\n",
    "        id_movies = data[:,1][data[:,0] == id_users]\n",
    "        id_ratings = data[:,2][data[:,0] == id_users]\n",
    "        ratings = np.zeros(nb_movies)\n",
    "        ratings[id_movies-1] = id_ratings\n",
    "        new_data.append(list(ratings))\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - CREATION OF THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caos_\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: tensor(1.7715)\n",
      "Epoch: 2, Loss: tensor(1.0967)\n",
      "Epoch: 3, Loss: tensor(1.0536)\n",
      "Epoch: 4, Loss: tensor(1.0383)\n",
      "Epoch: 5, Loss: tensor(1.0310)\n",
      "Epoch: 6, Loss: tensor(1.0268)\n",
      "Epoch: 7, Loss: tensor(1.0239)\n",
      "Epoch: 8, Loss: tensor(1.0220)\n",
      "Epoch: 9, Loss: tensor(1.0208)\n",
      "Epoch: 10, Loss: tensor(1.0195)\n",
      "Epoch: 11, Loss: tensor(1.0189)\n",
      "Epoch: 12, Loss: tensor(1.0184)\n",
      "Epoch: 13, Loss: tensor(1.0177)\n",
      "Epoch: 14, Loss: tensor(1.0177)\n",
      "Epoch: 15, Loss: tensor(1.0172)\n",
      "Epoch: 16, Loss: tensor(1.0169)\n",
      "Epoch: 17, Loss: tensor(1.0166)\n",
      "Epoch: 18, Loss: tensor(1.0165)\n",
      "Epoch: 19, Loss: tensor(1.0164)\n",
      "Epoch: 20, Loss: tensor(1.0162)\n",
      "Epoch: 21, Loss: tensor(1.0160)\n",
      "Epoch: 22, Loss: tensor(1.0158)\n",
      "Epoch: 23, Loss: tensor(1.0158)\n",
      "Epoch: 24, Loss: tensor(1.0159)\n",
      "Epoch: 25, Loss: tensor(1.0156)\n",
      "Epoch: 26, Loss: tensor(1.0158)\n",
      "Epoch: 27, Loss: tensor(1.0155)\n",
      "Epoch: 28, Loss: tensor(1.0152)\n",
      "Epoch: 29, Loss: tensor(1.0128)\n",
      "Epoch: 30, Loss: tensor(1.0121)\n",
      "Epoch: 31, Loss: tensor(1.0095)\n",
      "Epoch: 32, Loss: tensor(1.0092)\n",
      "Epoch: 33, Loss: tensor(1.0051)\n",
      "Epoch: 34, Loss: tensor(1.0051)\n",
      "Epoch: 35, Loss: tensor(1.0019)\n",
      "Epoch: 36, Loss: tensor(1.0018)\n",
      "Epoch: 37, Loss: tensor(0.9988)\n",
      "Epoch: 38, Loss: tensor(0.9980)\n",
      "Epoch: 39, Loss: tensor(0.9928)\n",
      "Epoch: 40, Loss: tensor(0.9933)\n",
      "Epoch: 41, Loss: tensor(0.9892)\n",
      "Epoch: 42, Loss: tensor(0.9910)\n",
      "Epoch: 43, Loss: tensor(0.9860)\n",
      "Epoch: 44, Loss: tensor(0.9887)\n",
      "Epoch: 45, Loss: tensor(0.9811)\n",
      "Epoch: 46, Loss: tensor(0.9874)\n",
      "Epoch: 47, Loss: tensor(0.9819)\n",
      "Epoch: 48, Loss: tensor(0.9855)\n",
      "Epoch: 49, Loss: tensor(0.9787)\n",
      "Epoch: 50, Loss: tensor(0.9852)\n",
      "Epoch: 51, Loss: tensor(0.9765)\n",
      "Epoch: 52, Loss: tensor(0.9750)\n",
      "Epoch: 53, Loss: tensor(0.9723)\n",
      "Epoch: 54, Loss: tensor(0.9754)\n",
      "Epoch: 55, Loss: tensor(0.9743)\n",
      "Epoch: 56, Loss: tensor(0.9728)\n",
      "Epoch: 57, Loss: tensor(0.9686)\n",
      "Epoch: 58, Loss: tensor(0.9676)\n",
      "Epoch: 59, Loss: tensor(0.9674)\n",
      "Epoch: 60, Loss: tensor(0.9738)\n",
      "Epoch: 61, Loss: tensor(0.9650)\n",
      "Epoch: 62, Loss: tensor(0.9644)\n",
      "Epoch: 63, Loss: tensor(0.9630)\n",
      "Epoch: 64, Loss: tensor(0.9599)\n",
      "Epoch: 65, Loss: tensor(0.9567)\n",
      "Epoch: 66, Loss: tensor(0.9576)\n",
      "Epoch: 67, Loss: tensor(0.9542)\n",
      "Epoch: 68, Loss: tensor(0.9550)\n",
      "Epoch: 69, Loss: tensor(0.9523)\n",
      "Epoch: 70, Loss: tensor(0.9532)\n",
      "Epoch: 71, Loss: tensor(0.9513)\n",
      "Epoch: 72, Loss: tensor(0.9535)\n",
      "Epoch: 73, Loss: tensor(0.9524)\n",
      "Epoch: 74, Loss: tensor(0.9531)\n",
      "Epoch: 75, Loss: tensor(0.9483)\n",
      "Epoch: 76, Loss: tensor(0.9507)\n",
      "Epoch: 77, Loss: tensor(0.9473)\n",
      "Epoch: 78, Loss: tensor(0.9485)\n",
      "Epoch: 79, Loss: tensor(0.9451)\n",
      "Epoch: 80, Loss: tensor(0.9469)\n",
      "Epoch: 81, Loss: tensor(0.9437)\n",
      "Epoch: 82, Loss: tensor(0.9454)\n",
      "Epoch: 83, Loss: tensor(0.9428)\n",
      "Epoch: 84, Loss: tensor(0.9434)\n",
      "Epoch: 85, Loss: tensor(0.9408)\n",
      "Epoch: 86, Loss: tensor(0.9416)\n",
      "Epoch: 87, Loss: tensor(0.9393)\n",
      "Epoch: 88, Loss: tensor(0.9406)\n",
      "Epoch: 89, Loss: tensor(0.9381)\n",
      "Epoch: 90, Loss: tensor(0.9389)\n",
      "Epoch: 91, Loss: tensor(0.9376)\n",
      "Epoch: 92, Loss: tensor(0.9392)\n",
      "Epoch: 93, Loss: tensor(0.9369)\n",
      "Epoch: 94, Loss: tensor(0.9371)\n",
      "Epoch: 95, Loss: tensor(0.9349)\n",
      "Epoch: 96, Loss: tensor(0.9363)\n",
      "Epoch: 97, Loss: tensor(0.9344)\n",
      "Epoch: 98, Loss: tensor(0.9356)\n",
      "Epoch: 99, Loss: tensor(0.9335)\n",
      "Epoch: 100, Loss: tensor(0.9349)\n",
      "Epoch: 101, Loss: tensor(0.9326)\n",
      "Epoch: 102, Loss: tensor(0.9342)\n",
      "Epoch: 103, Loss: tensor(0.9324)\n",
      "Epoch: 104, Loss: tensor(0.9337)\n",
      "Epoch: 105, Loss: tensor(0.9315)\n",
      "Epoch: 106, Loss: tensor(0.9324)\n",
      "Epoch: 107, Loss: tensor(0.9310)\n",
      "Epoch: 108, Loss: tensor(0.9323)\n",
      "Epoch: 109, Loss: tensor(0.9301)\n",
      "Epoch: 110, Loss: tensor(0.9314)\n",
      "Epoch: 111, Loss: tensor(0.9298)\n",
      "Epoch: 112, Loss: tensor(0.9310)\n",
      "Epoch: 113, Loss: tensor(0.9293)\n",
      "Epoch: 114, Loss: tensor(0.9301)\n",
      "Epoch: 115, Loss: tensor(0.9286)\n",
      "Epoch: 116, Loss: tensor(0.9297)\n",
      "Epoch: 117, Loss: tensor(0.9277)\n",
      "Epoch: 118, Loss: tensor(0.9287)\n",
      "Epoch: 119, Loss: tensor(0.9272)\n",
      "Epoch: 120, Loss: tensor(0.9284)\n",
      "Epoch: 121, Loss: tensor(0.9265)\n",
      "Epoch: 122, Loss: tensor(0.9275)\n",
      "Epoch: 123, Loss: tensor(0.9262)\n",
      "Epoch: 124, Loss: tensor(0.9273)\n",
      "Epoch: 125, Loss: tensor(0.9257)\n",
      "Epoch: 126, Loss: tensor(0.9265)\n",
      "Epoch: 127, Loss: tensor(0.9252)\n",
      "Epoch: 128, Loss: tensor(0.9261)\n",
      "Epoch: 129, Loss: tensor(0.9247)\n",
      "Epoch: 130, Loss: tensor(0.9256)\n",
      "Epoch: 131, Loss: tensor(0.9240)\n",
      "Epoch: 132, Loss: tensor(0.9251)\n",
      "Epoch: 133, Loss: tensor(0.9237)\n",
      "Epoch: 134, Loss: tensor(0.9243)\n",
      "Epoch: 135, Loss: tensor(0.9226)\n",
      "Epoch: 136, Loss: tensor(0.9239)\n",
      "Epoch: 137, Loss: tensor(0.9228)\n",
      "Epoch: 138, Loss: tensor(0.9233)\n",
      "Epoch: 139, Loss: tensor(0.9223)\n",
      "Epoch: 140, Loss: tensor(0.9228)\n",
      "Epoch: 141, Loss: tensor(0.9217)\n",
      "Epoch: 142, Loss: tensor(0.9221)\n",
      "Epoch: 143, Loss: tensor(0.9215)\n",
      "Epoch: 144, Loss: tensor(0.9217)\n",
      "Epoch: 145, Loss: tensor(0.9210)\n",
      "Epoch: 146, Loss: tensor(0.9212)\n",
      "Epoch: 147, Loss: tensor(0.9207)\n",
      "Epoch: 148, Loss: tensor(0.9208)\n",
      "Epoch: 149, Loss: tensor(0.9198)\n",
      "Epoch: 150, Loss: tensor(0.9205)\n",
      "Epoch: 151, Loss: tensor(0.9195)\n",
      "Epoch: 152, Loss: tensor(0.9202)\n",
      "Epoch: 153, Loss: tensor(0.9193)\n",
      "Epoch: 154, Loss: tensor(0.9198)\n",
      "Epoch: 155, Loss: tensor(0.9190)\n",
      "Epoch: 156, Loss: tensor(0.9196)\n",
      "Epoch: 157, Loss: tensor(0.9187)\n",
      "Epoch: 158, Loss: tensor(0.9192)\n",
      "Epoch: 159, Loss: tensor(0.9182)\n",
      "Epoch: 160, Loss: tensor(0.9186)\n",
      "Epoch: 161, Loss: tensor(0.9176)\n",
      "Epoch: 162, Loss: tensor(0.9181)\n",
      "Epoch: 163, Loss: tensor(0.9174)\n",
      "Epoch: 164, Loss: tensor(0.9177)\n",
      "Epoch: 165, Loss: tensor(0.9171)\n",
      "Epoch: 166, Loss: tensor(0.9178)\n",
      "Epoch: 167, Loss: tensor(0.9169)\n",
      "Epoch: 168, Loss: tensor(0.9172)\n",
      "Epoch: 169, Loss: tensor(0.9165)\n",
      "Epoch: 170, Loss: tensor(0.9173)\n",
      "Epoch: 171, Loss: tensor(0.9166)\n",
      "Epoch: 172, Loss: tensor(0.9167)\n",
      "Epoch: 173, Loss: tensor(0.9170)\n",
      "Epoch: 174, Loss: tensor(0.9162)\n",
      "Epoch: 175, Loss: tensor(0.9161)\n",
      "Epoch: 176, Loss: tensor(0.9164)\n",
      "Epoch: 177, Loss: tensor(0.9154)\n",
      "Epoch: 178, Loss: tensor(0.9156)\n",
      "Epoch: 179, Loss: tensor(0.9152)\n",
      "Epoch: 180, Loss: tensor(0.9152)\n",
      "Epoch: 181, Loss: tensor(0.9149)\n",
      "Epoch: 182, Loss: tensor(0.9149)\n",
      "Epoch: 183, Loss: tensor(0.9149)\n",
      "Epoch: 184, Loss: tensor(0.9147)\n",
      "Epoch: 185, Loss: tensor(0.9146)\n",
      "Epoch: 186, Loss: tensor(0.9144)\n",
      "Epoch: 187, Loss: tensor(0.9144)\n",
      "Epoch: 188, Loss: tensor(0.9141)\n",
      "Epoch: 189, Loss: tensor(0.9139)\n",
      "Epoch: 190, Loss: tensor(0.9139)\n",
      "Epoch: 191, Loss: tensor(0.9135)\n",
      "Epoch: 192, Loss: tensor(0.9137)\n",
      "Epoch: 193, Loss: tensor(0.9139)\n",
      "Epoch: 194, Loss: tensor(0.9136)\n",
      "Epoch: 195, Loss: tensor(0.9136)\n",
      "Epoch: 196, Loss: tensor(0.9133)\n",
      "Epoch: 197, Loss: tensor(0.9131)\n",
      "Epoch: 198, Loss: tensor(0.9130)\n",
      "Epoch: 199, Loss: tensor(0.9131)\n",
      "Epoch: 200, Loss: tensor(0.9130)\n"
     ]
    }
   ],
   "source": [
    "# Use the function to extract the data\n",
    "training_set = convert(training_set)\n",
    "test_set = convert(test_set)\n",
    "\n",
    "# Convert data to Torch tensors\n",
    "training_set = torch.FloatTensor(training_set)\n",
    "test_set = torch.FloatTensor(test_set)\n",
    "\n",
    "#Creating the architecture of the Neural Network\n",
    "class SAE(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(SAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(nb_movies, 20) #first hidden layer that has 20 neurons\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        self.fc3 = nn.Linear(10, 20)  #fc = full conected\n",
    "        self.fc4 = nn.Linear(20, nb_movies)\n",
    "        self.activation = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.activation(self.fc3(x))\n",
    "        x = self.fc4(x) ##To replicate the input, we cannot put a sigmoid output unless we first encode the input in the appropriate range, but that is not what we are looking for in this case.\n",
    " \n",
    "        return x\n",
    "    \n",
    "\n",
    "sae = SAE()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(sae.parameters(), lr= 0.01, weight_decay= 0.5 ) #weight_decay = LR decay to adjust as iterations progress the lr // parameters is inherited from Module to transmit the parameters.\n",
    "\n",
    "# Training the SAE\n",
    "nb_epoch = 200\n",
    "for epoch in range(1,nb_epoch+1):\n",
    "    train_loss = 0 \n",
    "    s = 0.\n",
    "    for id_user in range(nb_users):\n",
    "        input = Variable(training_set[id_user]).unsqueeze(0) #We need the input to be an array, not a list of vectors, so we add a dimension with Variable that we have imported and then the unsqueeze method.\n",
    "        target = input.clone()\n",
    "        if torch.sum(target.data > 0) >0: # we add a vector that gives you true if it is greater than 0, so if there are 27 rated films it will be greater than 1 and will pass if there are no ratings it does not pass.\n",
    "            output = sae.forward(input)\n",
    "            target.requires_grad = False\n",
    "            output[target == 0] = 0\n",
    "            loss = criterion(output, target)\n",
    "            mean_corrector = nb_movies/float(torch.sum(target.data > 0)+ 1e-10) #We want to see an overall average error rate for rating films, so we look at how many films you have rated out of the total, the 1e-10 is so that it never crashes, if the sum is 0.\n",
    "            loss.backward() #propagate error backwards // only decides the direction of the weights.\n",
    "            train_loss += np.sqrt(loss.data*mean_corrector) #where is the error in loss.data. We correct the data with the previous factor. Be careful the MSE is squared, we need to square root it.  ## sum(errors) / n_valued_films\n",
    "            s += 1.\n",
    "            optimizer.step()  #The optimiser decides HOW MUCH to multiply the weights to get to what we want, but not the direction.\n",
    "            \n",
    "    print(\"Epoch: \" + str(epoch) + \", Loss: \" + str(train_loss/s))     \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 3 - EVALUATION OF THE MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: tensor(1.8757)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the test assembly\n",
    "test_loss = 0 \n",
    "s = 0.\n",
    "for id_user in range(nb_users):\n",
    "    input = Variable(training_set[id_user]).unsqueeze(0)  #You need the input to be an array, not a list of vectors, so you add a dimension with Variable that we have imported and then the unsqueeze method.\n",
    "    target = Variable(test_set[id_user]).unsqueeze(0) \n",
    "    if torch.sum(target.data > 0) >0: # we add a vector that gives you true if it is greater than 0, so if there are 27 rated films it will be greater than 1 and will pass if there are no ratings it does not pass.\n",
    "        output = sae.forward(input)\n",
    "        target.requires_grad = False #the target set remains unchanged we save caclulus\n",
    "        output[target == 0] = 0 # this makes sense in the test, but in the future we would have to remove it to see ALL RATINGS not just the test score.\n",
    "        test_loss = criterion(output, target)\n",
    "        mean_corrector = nb_movies/float(torch.sum(target.data > 0)+ 1e-10) #We want to see an overall average error rate for rating films, so we look at how many films you have rated out of the total, the 1e-10 is so that it never crashes, if the sum is 0.\n",
    "        test_loss += np.sqrt(loss.data*mean_corrector)\n",
    "        s += 1.\n",
    "    \n",
    "print(\"Test Loss: \" + str(train_loss/s))     \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how in this case we have an average error of 1.87 stars in the films we have evaluated, in this case it is quite large, if it were not a case study to see how an autoencoder works now we would have to modify parameters to reduce this error to less than 1 average star. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
